# CIFAR-100 Perceiver Configuration
device: "cuda"

# Model Architecture
model:
  input_dim: 37
  depth: 8
  output_dim: 100
  num_latents: 256
  latent_dim: 384
  cross_heads: 1
  cross_head_dim: 64
  cross_rotary_emb_dim: 0
  cross_attn_dropout: 0.1
  latent_heads: 8
  latent_head_dim: 64
  latent_rotary_emb_dim: 0
  latent_attn_dropout: 0.1
  latent_drop: 0.1
  weight_tie_layers: true
  gated_mlp: false
  self_per_cross_attn: 5
  output_mode: "average"
  num_zero_tokens: null
  use_flash_attn: true

# Positional Encoding
pos_encoding:
  bands: 8
  dims: 2
  max_res: 32

# Training Parameters
training:
  lr: 0.004
  weight_decay: 0.3
  batch_size: 128
  gradient_accumulation_steps: 8
  epochs: 300
  data_root: "../data"
  checkpoint_interval: 10  # Save checkpoints every N epochs
  num_workers: 4

# Optimizer Configuration
optimizer:
  type: "adamw"
  betas: [0.9, 0.95]
  eps: 1.0e-8

# Data Augmentation
augmentation:
  # Options: 'standard', 'randaug', 'moco'
  type: "moco"  # MoCo-style augmentation
  # MoCo augmentation parameters
  resize_scale: [0.2, 1.0]  # Scale range for RandomResizedCrop
  grayscale_p: 0.2  # Probability for RandomGrayscale
  jitter_brightness: 0.4  # ColorJitter brightness
  jitter_contrast: 0.4  # ColorJitter contrast
  jitter_saturation: 0.4  # ColorJitter saturation
  jitter_hue: 0.4  # ColorJitter hue
  # RandAugment parameters (used only if type is 'randaug')
  # randaug_n: 2  # Number of augmentations to apply
  # randaug_m: 10  # Magnitude of augmentations

# Learning Rate Scheduler
scheduler:
  type: "cosine"
  # For epoch-based warmup
  # warmup_steps: null
  warmup_epochs: 20
  # Minimum learning rate (absolute value)
  min_lr: 0.000001 # Use this instead of min_rl

# Logging
logging:
  use_tensorboard: true
  logdir: "./logs" 